% Controllable Text Generation
%[1]
@inproceedings{
dekoninck2024controlled,
title={Controlled Text Generation via Language Model Arithmetic},
author={Jasper Dekoninck and Marc Fischer and Luca Beurer-Kellner and Martin Vechev},
booktitle={Proceedings of the Twelfth International Conference on Learning Representations (ICLR)},
year={2024},
}
%[2]
@inproceedings{chen2024benchmarking,
  title={Benchmarking Large Language Models on Controllable Generation under Diversified Instructions},
  author={Chen, Yihan and Xu, Benfeng and Wang, Quan and Liu, Yi and Mao, Zhendong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
  volume={38},
  number={16},
  pages={17808--17816},
  year={2024}
}
%[3]
@inproceedings{sun2023evaluating,
  title={Evaluating Large Language Models on Controlled Generation Tasks},
  author={Sun, Jiao and Tian, Yufei and Zhou, Wangchunshu and Xu, Nan and Hu, Qian and Gupta, Rahul and Wieting, John and Peng, Nanyun and Ma, Xuezhe},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={3155--3168},
  year={2023}
}

% Alignment
%[4]
@inproceedings{
wang2024promptagent,
title={PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization},
author={Xinyuan Wang and Chenxi Li and Zhen Wang and Fan Bai and Haotian Luo and Jiayou Zhang and Nebojsa Jojic and Eric Xing and Zhiting Hu},
booktitle={Proceedings of the Twelfth International Conference on Learning Representations (ICLR)},
year={2024},
}
%[5] 
@article{liang2023encouraging,
  title={Encouraging divergent thinking in large language models through multi-agent debate},
  author={Liang, Tian and He, Zhiwei and Jiao, Wenxiang and Wang, Xing and Wang, Yan and Wang, Rui and Yang, Yujiu and Tu, Zhaopeng and Shi, Shuming},
  journal={arXiv preprint arXiv:2305.19118},
  year={2023}
}
%[6]
@inproceedings{deng2023prompting,
  title={Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration},
  author={Deng, Yang and Liao, Lizi and Liang, CHEN and Hongru, WANG and Lei, Wenqiang and Chua, Tat-Seng},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={10602--10621},
  year={2023}
}
%[7]
@article{abramson2022evaluating,
  title={Evaluating Multimodal Interactive Agents},
  author={Abramson, Josh and Ahuja, Arun and Carnevale, Federico and Georgiev, Petko and Goldin, Alex and Hung, Alden and Landon, Jessica and Lillicrap, Timothy and Muldal, Alistair and Richards, Blake and others},
  journal={arXiv preprint arXiv:2205.13274},
  year={2022}
}

% [8]
@article{dong2022survey,
  title={A Survey on In-context Learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Wu, Zhiyong and Chang, Baobao and Sun, Xu and Xu, Jingjing and Sui, Zhifang},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022}
}
% [9]
@article{dong2023survey,
  title={A survey on long text modeling with transformers},
  author={Dong, Zican and Tang, Tianyi and Li, Lunyi and Zhao, Wayne Xin},
  journal={arXiv preprint arXiv:2302.14502},
  year={2023}
}
% [10]
@article{dong2023survey,
  title={A survey on long text modeling with transformers},
  author={Dong, Zican and Tang, Tianyi and Li, Lunyi and Zhao, Wayne Xin},
  journal={arXiv preprint arXiv:2302.14502},
  year={2023}
}